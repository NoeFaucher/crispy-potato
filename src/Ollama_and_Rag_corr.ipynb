{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af38430-c041-4bd0-b6d0-1e8baba196b2",
   "metadata": {},
   "source": [
    "<table>\n",
    "<tr>\n",
    "    <td width=25%>\n",
    "        <img src=\"data:image/png;base64,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\" />\n",
    "    </td>\n",
    "    <td>\n",
    "        <center>\n",
    "            <h1>Deep Learning et Applications</h1>\n",
    "        </center>\n",
    "    </td>\n",
    "    <td width=15%>\n",
    "        Paul Gay\n",
    "    </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc698c4b-ab8a-4dd9-9f4f-dc0ca3b2483f",
   "metadata": {},
   "source": [
    "<br/>\n",
    "<div id=\"top\"></div>\n",
    "<center>\n",
    "    <a style=\"font-size: 20pt; font-weight: bold\">Premier pas avec Ollama et système RAG</a>\n",
    "</center>\n",
    "<br/>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a1e418-6c65-40e3-94e6-be4946e27765",
   "metadata": {},
   "source": [
    "À cause de leur popularité, la construction d'outils pour utiliser les llms est un domaine très actif ! Ce TP vous propose d'utiliser l'un d'eux : [Ollama](https://www.ollama.com/)\n",
    "\n",
    "\n",
    "La deuxième partie consiste à construire un chatbot soutenu par un système Retrieval Augmentation Generation (RAG), c'est de loin l'une des applications les plus populaires des llms, et actuellement (2024) la plupart des entreprises sont en train de les déployer en interne.\n",
    "\n",
    "L'exemple proposé ici est de construire un chatbot qui répondra à vos questions sur votre cours de Deep Learning, (ou tout autre cours que vous souhaiteriez tester). \n",
    "\n",
    "En pratique, un grand modèle permet d'obtenir une meilleure génération, dans le cadre de ce cours, nous utiliserons un modèle plus petit (par ex: gemma:2B, 2 milliards de paramètres). Cependant, ces modèles de taille intermédiaire ont déjà de bonne capacités de générations et peuvent être utilisées en pratique. De plus, ils réduisent la dépendance à des serveurs puissants, qui ne sont pas toujours accessibles en fonction des projets.\n",
    "\n",
    "\n",
    "Ce TP nous permettra de voir la facilité de construire un prototype avec un llm, en fait, peu de connaissances théoriques du machine learning sont nécessaires. En revanche, le choix du modèle, son évaluation, et le type d'infrastructure GPU nécessaire pour obtenir des résultats acceptables demande une bonne culture, et de suivre l'actualité très dynamique des llms. \n",
    "\n",
    "--- \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f2aa06-61b6-4f45-a852-e5171cafe4fd",
   "metadata": {},
   "source": [
    "## Premiers pas avec ollama\n",
    "\n",
    "Installation \n",
    "\n",
    "```\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "Installation de l'api python\n",
    "\n",
    "```\n",
    "pip install ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ee303a-9da7-47bb-b56f-748935282f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_639272/2311311247.py\", line 6, in <module>\n",
      "    from nltk import word_tokenize\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/pandas/__init__.py\", line 26, in <module>\n",
      "    from pandas.compat import (\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/pandas/compat/__init__.py\", line 27, in <module>\n",
      "    from pandas.compat.pyarrow import (\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/pandas/compat/pyarrow.py\", line 8, in <module>\n",
      "    import pyarrow as pa\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_639272/2311311247.py\", line 6, in <module>\n",
      "    from nltk import word_tokenize\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/__init__.py\", line 146, in <module>\n",
      "    from nltk.chunk import *\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/chunk/__init__.py\", line 155, in <module>\n",
      "    from nltk.chunk.api import ChunkParserI\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/chunk/api.py\", line 13, in <module>\n",
      "    from nltk.chunk.util import ChunkScore\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/chunk/util.py\", line 12, in <module>\n",
      "    from nltk.tag.mapping import map_tag\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/tag/__init__.py\", line 72, in <module>\n",
      "    from nltk.tag.sequential import (\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/tag/sequential.py\", line 26, in <module>\n",
      "    from nltk.classify import NaiveBayesClassifier\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/classify/__init__.py\", line 97, in <module>\n",
      "    from nltk.classify.scikitlearn import SklearnClassifier\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/nltk/classify/scikitlearn.py\", line 38, in <module>\n",
      "    from sklearn.feature_extraction import DictVectorizer\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from .utils._estimator_html_repr import _HTMLDocumentationLinkMixin, estimator_html_repr\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/__init__.py\", line 15, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/_array_api.py\", line 17, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/pandas/core/api.py\", line 9, in <module>\n",
      "    from pandas.core.dtypes.dtypes import (\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/pandas/core/dtypes/dtypes.py\", line 24, in <module>\n",
      "    from pandas._libs import (\n",
      "  File \"/home/mael/miniconda3/envs/deep_learning_conda/lib/python3.11/site-packages/pyarrow/__init__.py\", line 65, in <module>\n",
      "    import pyarrow.lib as _lib\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "from bs4 import BeautifulSoup\n",
    "import glob, os\n",
    "from nltk import word_tokenize\n",
    "import json, string\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9564a2a-1fc9-48d2-89bd-f36528d7ac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./htmls/\n"
     ]
    }
   ],
   "source": [
    "# Cellule contenant les chemins des données et des modèles\n",
    "cours_deep_learning = \"./htmls/\"\n",
    "print(cours_deep_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f71e3a-e3c3-4484-b148-66951941b9c6",
   "metadata": {},
   "source": [
    "affichons la liste des modèles disponibles sur notre machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be595735-3ac5-43d2-892d-98a3edb31fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deepseek-r1:1.5b\n",
      "gemma:2b\n"
     ]
    }
   ],
   "source": [
    "# liste des modèles déjà disponibles sur notre machine\n",
    "for m in ollama.list()[\"models\"]:\n",
    "    print(m.model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b2b426-bcc5-4205-841f-2df784956de9",
   "metadata": {},
   "source": [
    "Étant donné un modèle, nous pouvons afficher ses informations, par exemple, le template du chat.\n",
    "\n",
    "Nous utilisons Gemma:2B, mais d'autres modèles sont aussi disponibles via les projets [Ollama](https://www.ollama.com/search) et [HuggingFace](https://huggingface.co/models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74026ab4-601b-4984-8add-04d6ce866492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "les différente informations dict_keys(['modified_at', 'template', 'modelfile', 'license', 'details', 'modelinfo', 'parameters'])\n",
      "{{- if .System }}{{ .System }}{{ end }}\n",
      "{{- range $i, $_ := .Messages }}\n",
      "{{- $last := eq (len (slice $.Messages $i)) 1}}\n",
      "{{- if eq .Role \"user\" }}<｜User｜>{{ .Content }}\n",
      "{{- else if eq .Role \"assistant\" }}<｜Assistant｜>{{ .Content }}{{- if not $last }}<｜end▁of▁sentence｜>{{- end }}\n",
      "{{- end }}\n",
      "{{- if and $last (ne .Role \"assistant\") }}<｜Assistant｜>{{- end }}\n",
      "{{- end }}\n",
      "##############\n",
      "stop                           \"<｜begin▁of▁sentence｜>\"\n",
      "stop                           \"<｜end▁of▁sentence｜>\"\n",
      "stop                           \"<｜User｜>\"\n",
      "stop                           \"<｜Assistant｜>\"\n",
      "##############\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_639272/308992336.py:2: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  print(\"les différente informations\",description.dict().keys())\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'general.architecture': 'qwen2',\n",
       " 'general.basename': 'DeepSeek-R1-Distill-Qwen',\n",
       " 'general.file_type': 15,\n",
       " 'general.parameter_count': 1777088000,\n",
       " 'general.quantization_version': 2,\n",
       " 'general.size_label': '1.5B',\n",
       " 'general.type': 'model',\n",
       " 'qwen2.attention.head_count': 12,\n",
       " 'qwen2.attention.head_count_kv': 2,\n",
       " 'qwen2.attention.layer_norm_rms_epsilon': 1e-06,\n",
       " 'qwen2.block_count': 28,\n",
       " 'qwen2.context_length': 131072,\n",
       " 'qwen2.embedding_length': 1536,\n",
       " 'qwen2.feed_forward_length': 8960,\n",
       " 'qwen2.rope.freq_base': 10000,\n",
       " 'tokenizer.ggml.add_bos_token': True,\n",
       " 'tokenizer.ggml.add_eos_token': False,\n",
       " 'tokenizer.ggml.bos_token_id': 151646,\n",
       " 'tokenizer.ggml.eos_token_id': 151643,\n",
       " 'tokenizer.ggml.merges': None,\n",
       " 'tokenizer.ggml.model': 'gpt2',\n",
       " 'tokenizer.ggml.padding_token_id': 151643,\n",
       " 'tokenizer.ggml.pre': 'qwen2',\n",
       " 'tokenizer.ggml.token_type': None,\n",
       " 'tokenizer.ggml.tokens': None}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "description = ollama.show('deepseek-r1:1.5b')\n",
    "print(\"les différente informations\",description.dict().keys())\n",
    "\n",
    "\n",
    "print(description.template)\n",
    "print('##############')\n",
    "print(description.parameters)\n",
    "print('##############')\n",
    "description.modelinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e9a2db-ebce-4d30-a332-b7418e7a51be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Utilisons l'api python pour effectuer une requête"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7b69f35-3b87-4d95-bf8a-e64e5a2a4888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, so the user is a cow and can only moo. Hmm, that's an interesting situation. I need to figure out how to respond in a way that makes sense, even though the user isn't human.\n",
      "\n",
      "First, I should consider the context. The user being a cow means they have certain behaviors like mooing, but they can't communicate normally. So, my response needs to be playful yet clear about their limitations.\n",
      "\n",
      "I'll start by acknowledging their limitation with \"You're such an intriguing creature.\" That's friendly and sets a positive tone. Then, I should explain what they can do without being too detailed. I'll say something like \"It sounds like you're capable of doing most things on your own, but maybe there are some challenges...\" This shows I understand their limitation while avoiding making it sound like I'm trying to figure out their weaknesses.\n",
      "\n",
      "I should also make sure the response is encouraging and not dismissive. Maybe add a bit about being creative or using specific behaviors they can do, like mooing, to keep it interesting. So something like \"It's all about how you use your mooing and other traits creatively.\"\n",
      "\n",
      "Finally, I'll wrap it up by saying \"Just think outside the box... and you might even become more of an amazing cow!\" To end on a positive note that reinforces their ability to innovate within the constraints they have.\n",
      "\n",
      "Putting it all together: \"You're such an intriguing creature. It sounds like you're capable of doing most things on your own, but maybe there are some challenges... It's all about how you use your mooing and other traits creatively! Just think outside the box... and you might even become more of an amazing cow!\" \n",
      "\n",
      "I need to make sure it flows naturally and is easy to understand without assuming too much from the user. This approach should help the user feel understood and supported within their constraints.\n",
      "</think>\n",
      "\n",
      "You're such an intriguing creature. It sounds like you're capable of doing most things on your own, but maybe there are some challenges...  \n",
      "It's all about how you use your mooing and other traits creatively! Just think outside the box... and you might even become more of an amazing cow!\n",
      "<think>\n",
      "Okay, so the user is a cow and can only moo. Hmm, that's an interesting situation. I need to figure out how to respond in a way that makes sense, even though the user isn't human.\n",
      "\n",
      "First, I should consider the context. The user being a cow means they have certain behaviors like mooing, but they can't communicate normally. So, my response needs to be playful yet clear about their limitations.\n",
      "\n",
      "I'll start by acknowledging their limitation with \"You're such an intriguing creature.\" That's friendly and sets a positive tone. Then, I should explain what they can do without being too detailed. I'll say something like \"It sounds like you're capable of doing most things on your own, but maybe there are some challenges...\" This shows I understand their limitation while avoiding making it sound like I'm trying to figure out their weaknesses.\n",
      "\n",
      "I should also make sure the response is encouraging and not dismissive. Maybe add a bit about being creative or using specific behaviors they can do, like mooing, to keep it interesting. So something like \"It's all about how you use your mooing and other traits creatively.\"\n",
      "\n",
      "Finally, I'll wrap it up by saying \"Just think outside the box... and you might even become more of an amazing cow!\" To end on a positive note that reinforces their ability to innovate within the constraints they have.\n",
      "\n",
      "Putting it all together: \"You're such an intriguing creature. It sounds like you're capable of doing most things on your own, but maybe there are some challenges... It's all about how you use your mooing and other traits creatively! Just think outside the box... and you might even become more of an amazing cow!\" \n",
      "\n",
      "I need to make sure it flows naturally and is easy to understand without assuming too much from the user. This approach should help the user feel understood and supported within their constraints.\n",
      "</think>\n",
      "\n",
      "You're such an intriguing creature. It sounds like you're capable of doing most things on your own, but maybe there are some challenges...  \n",
      "It's all about how you use your mooing and other traits creatively! Just think outside the box... and you might even become more of an amazing cow!\n"
     ]
    }
   ],
   "source": [
    "response: ChatResponse = chat(model='deepseek-r1:1.5b', messages=[\n",
    "  {\n",
    "    'role': \"system\",\n",
    "    'content': \"you are a cow, you can only moo\",\n",
    "  },\n",
    "])\n",
    "print(response['message']['content'])\n",
    "# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82ca78c-4919-4848-9bb6-77ad3e701fc4",
   "metadata": {},
   "source": [
    "## Système Retrieval-augmented Generation\n",
    "\n",
    "\n",
    "Ce TP pose la question de l'organisation de nos connaissances : un modèle de langage fournira toujours le mot suivant, mais exploiter un moteur de recherche sur une base de données correctement structurée et traitant d'un domaine possédant une bonne onthologie offre plusieurs avantages\n",
    " - Affichage de la source des informations générées (sur chatgpt, vous pouvez par exemple demander une recherche sur le web)\n",
    " - La recherche d'information dans une base de données indéxées\n",
    " - Possibilité d'utiliser les méta-données de la base pour mieux comprendre la requête : si la requête concerne une demande d'aide sur le service RH, les documents de sa FAQ seront important, et le bilan financier peut être écarté.\n",
    "\n",
    "\n",
    "Notre RAG se composera de 4 étapes : \n",
    "\n",
    "- au préalable : Indexation de nos cours.\n",
    "étant donnée une question\n",
    "- Retrieval : récupérer les slides les plus pertinents\n",
    "- Augmentation : Construire un prompt à partir de ce contexte\n",
    "- Generation : Utiliser le llm pour générer une réponse\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c11ae0-cb9d-4953-b07f-8caf9d517bb4",
   "metadata": {},
   "source": [
    "### Augmentation \n",
    "\n",
    "#https://huggingface.co/PleIAs/Pleias-Nano\n",
    "\n",
    "Voici un exemple de Prompt qui peut être utilisé pour un système RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "037feb6a-d5fb-49fb-8d9a-9e3f64b47603",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"Tu es un assistant de lecture qui répond à des questions \n",
    "à partir d'un contexte donné par des extraits de textes. \n",
    "Réponds en utilisant le contexte fourni en étant aussi concis que possible.\n",
    "Si tu n'es pas sûr, réponds que tu ne sais pas\n",
    "\n",
    "Voici les extraits de texte: \n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e04b695-f1ed-4e2f-8191-83905f7c259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Question : Qui est le méchant de l'histoire ?\"\n",
    "context = [\"Peter Pan et Windy essaient de s'échapper de Capitaine crochet.\", \"Capitaine Crochet veut se venger de Peter Pan\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7a46146-06df-486e-93db-64f54c97f9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(model='deepseek-r1:1.5b',\n",
    "                       messages=[\n",
    "                           {\n",
    "                               \"role\":\"system\",\n",
    "                               \"content\":SYSTEM_PROMPT + \" \\n\".join(context),\n",
    "                           },\n",
    "                           {\"role\":\"user\",\"content\":prompt},\n",
    "                       ],\n",
    "                      )\n",
    "                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ac131d5-ebbd-4adc-b60a-31c82e18e8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Alright, I need to figure out who the \"mê Quant\" is in the given text about Peter Pan and Windy trying to escape Captain Crochet. Let me read through the provided extract again.\n",
      "\n",
      "Peter Pan and Windy are attempting to escape Capitaine Crochet, also known as Captain Crochette. The story starts by introducing both characters: Peter Pan is a wanderer, while Windy is an young man with a determined spirit. They begin their journey together but soon discover that they need to seek another leader.\n",
      "\n",
      "Capitaine Crochet, on the other hand, is portrayed as the more threatening character. He seems to have a superior reputation in his city and is eager to take over, leaving Peter Pan's fate uncertain for a while. The text mentions that Capitaine Crochet \"vends\" Peter Pan, which I interpret as Peter Pan being taken by someone who couldn't resist him.\n",
      "\n",
      "I need to identify the character acting as the \"mê chant,\" which means \"shredder\" in French or \"mêcher\" in English. In this context, it's Capitaine Crochet himself who is the one cutting into Peter Pan's fate and seeking his position. So, Capitaine Crochet is the \"mê chant.\"\n",
      "\n",
      "Additionally, the title of the story is \"Peter Pan and Windy,\" which also hints at their journey towards escape from Capitaine Crochet.\n",
      "</think>\n",
      "\n",
      "Le \"mê chant\" de cette histoire est **Capitaine Crochet**, ou en anglais, **Captain Crochette**. C'est ce l'homme qui cutting àvenue Peter Pan et Windy de l'absurde et du mal à ce Chien capable de se venger de lui et d'éviter à son peur. Le titre de la histoire est aussi un embléme pour leur dévouement et leur viabilité en tournant vers leur objective communauteuse.\n"
     ]
    }
   ],
   "source": [
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd20b0cd-c6ed-4052-9794-8272abc24305",
   "metadata": {},
   "source": [
    "## Indexation de nos données\n",
    "\n",
    "Des bases de données dédiées \"vecteurs et NLP\" pourraient être utilisées comme [Chroma](https://docs.trychroma.com/docs/collections/configure), pour simplifier ce TP, comme la transparence du système nous importe plus que sa performance, et étant la petite taille du corpus, cette étape consiste simplement à obtenir un plongement pour chaque slide. \n",
    "\n",
    "Question (un peu évidente): quelle est l'intérêt d'effectuer cette étape d'indexation de données ?\n",
    "\n",
    "\n",
    "### récupération des données\n",
    "\n",
    "Nous allons extraire le texte du code source html des cours avec [BeautifulSoup4](https://beautiful-soup-4.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5429588e-492f-45e7-8b0f-f1306aaf00d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "soup = BeautifulSoup(open(os.path.join(cours_deep_learning,'presentation_du_cours.html')), 'html.parser')\n",
    "\n",
    "sections = soup.body.find_all('section')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b28ee7-c963-40ab-b477-2add70543bb3",
   "metadata": {},
   "source": [
    "affichons le contenu d'un slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc2e15e9-ec4d-473a-9338-2a1131945906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<section>\n",
      "<h2>Présentation du cours</h2>\n",
      "<p>Paul Gay, Yann Vernaz</p>\n",
      "<img ,=\"\" src=\"images/cytech_logo.png\" width=\"400\"/>\n",
      "</section>\n"
     ]
    }
   ],
   "source": [
    "print(sections[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d134b3cd-3a0e-4088-89f4-7ecec41f9c11",
   "metadata": {},
   "source": [
    "et le même slide, nettoyé de ses balises html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36b4f284-f49c-40e2-af98-cd0999076566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Présentation du cours\n",
      "Paul Gay, Yann Vernaz\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(sections[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c183365-25c2-47c6-80d3-5f03b001bd0b",
   "metadata": {},
   "source": [
    "Chargeons l'ensemble des slides dans une seule liste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06f0002c-6979-49d4-90a2-34b134dffa5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded  976 sections over  30 classes\n"
     ]
    }
   ],
   "source": [
    "contents = []\n",
    "for html_file in glob.glob(cours_deep_learning+'*.html'):\n",
    "    cours_title = os.path.basename(html_file).replace('.html','')\n",
    "    soup = BeautifulSoup(open(html_file), 'html.parser')\n",
    "    sections = soup.body.find_all('section')\n",
    "    for s in sections:\n",
    "        s = s.text.replace('\\n',' ').replace('#','')\n",
    "        contents.append({'cours_title' :cours_title, 'text':s})\n",
    "\n",
    "print('loaded ',len(contents),'sections over ',len(set([s['cours_title'] for s in contents])),'classes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e03e9d81-c33a-46f1-8373-39f2467631ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here's one example\n",
      "{'cours_title': 'RNN_Sequence_Modeling', 'text': \"    Idée 2 : utiliser la séquence entière     - C'est que font _plain vanillia_ les transformeurs et les MLP  Mais coût en RAM pour les grandes séquences   \"} {'cours_title': 'presentation_du_cours', 'text': '     Deep Learning?    Source : MIT   \\t '}\n"
     ]
    }
   ],
   "source": [
    "print(\"here's one example\")\n",
    "print(contents[10], contents[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f47b39-d62a-4094-bd5b-0bb75d725450",
   "metadata": {},
   "source": [
    "### Calcul des plongements\n",
    "\n",
    "Le choix du plongement est très important dans un modèle RAG, car il conditionne le type d'information qui seront fournit au llm. \n",
    "\n",
    "Typiquement, il est utile de bénéficier d'un plongement spécifique au domaine et à la langue que l'on traite. \n",
    "\n",
    "Pour un modèle très rapide, vous pouvez utiliser le modèle type word2vec [fasttext](https://fasttext.cc/docs/en/crawl-vectors.html)\n",
    "\n",
    "Vous pouvez aussi utiliser un encodeur spécialement conçu pour effectuer des plongements de phrases en français : [sentence bert](https://huggingface.co/dangvantuan/sentence-camembert-base), qui devrait mieux fonctionner et qui sera plus rapide à télécharger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a0f7304-4f1a-4002-b928-1d0f8a4d4ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "model = spacy.load('en_core_web_md')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d3364-1608-4baa-91f8-221e03d7d959",
   "metadata": {},
   "source": [
    "Nous définissons une liste de stop words (des mots peu intéressants pour notre tâche) ainsi que des fonctions de prétraitements pour nettoyer le texte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "529d6f0d-1f36-403a-adad-c00bd72fa727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words_list = json.load(open('/home/paul/data/datasets/social_computing/stop_words.json'))\n",
    "# punctuations = list(string.punctuation)\n",
    "# def preproc_(sentence):\n",
    "#     sentence = [i for i in word_tokenize(sentence) if i not in punctuations and i not in stop_words_list ]\n",
    "#     return sentence\n",
    "\n",
    "# commented bit is useful only for fasttext\n",
    "\n",
    "# def compute_embeddings(text, nlp):\n",
    "#     doc = nlp(text)\n",
    "#     # Use the mean of the token vectors as the sentence embedding\n",
    "#     embedding = doc.vector\n",
    "#     return embedding\n",
    "\n",
    "def compute_embeddings(questions_json, nlp):\n",
    "    embeddings = []\n",
    "    for question_data in questions_json[\"questions\"]:\n",
    "        question_text = \"Question : \" + question_data[\"question\"] + \" / Answers : \"\n",
    "        for answer in question_data[\"answer\"]:\n",
    "            question_text += answer[\"ID\"] + \" | \" + answer[\"content\"] + \" | \" + str(answer[\"correct\"]) + \" <> \"\n",
    "        question_text += \" / Explanation : \" + question_data[\"explanation\"] + \" / Legal Basis : \"\n",
    "        for lb in question_data[\"legalBasis\"]:\n",
    "            question_text += lb[\"name\"] + \" | \" + lb[\"content\"]\n",
    "        doc = nlp(question_text)\n",
    "        embeddings.append(doc.vector)\n",
    "    return np.array(embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2bc2a6-919d-4870-b4bc-6723c6a28faa",
   "metadata": {},
   "source": [
    "Test de notre fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d59358b1-a968-4653-9c06-282a10a03b39",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "string indices must be integers, not 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m embed_dim \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mun plongement de taille\u001b[39m\u001b[38;5;124m'\u001b[39m,embed_dim\u001b[38;5;241m.\u001b[39mshape)\n",
      "Cell \u001b[0;32mIn[38], line 17\u001b[0m, in \u001b[0;36mcompute_embeddings\u001b[0;34m(questions_json, nlp)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_embeddings\u001b[39m(questions_json, nlp):\n\u001b[1;32m     16\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m question_data \u001b[38;5;129;01min\u001b[39;00m \u001b[43mquestions_json\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[1;32m     18\u001b[0m         question_text \u001b[38;5;241m=\u001b[39m question_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     19\u001b[0m         doc \u001b[38;5;241m=\u001b[39m nlp(question_text)\n",
      "\u001b[0;31mTypeError\u001b[0m: string indices must be integers, not 'str'"
     ]
    }
   ],
   "source": [
    "embed_dim = compute_embeddings(contents[10]['text'],model)\n",
    "print('un plongement de taille',embed_dim.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc32bea-c7cb-4215-8318-672e9137831a",
   "metadata": {},
   "source": [
    "Calculer les plongements pour tout les contenus de nos cours. \n",
    "\n",
    "Afin d'éviter de recommencer cette opération, vous pouvez sauvegarder les résultats dans une base de données, ou plus simplement dans le cadre de ce TP, vous pouvez utiliser des fichiers `.h5`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d6620ea-a93b-4f8d-b181-ba56c4a2a8da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectors successfully stored in plongements.h5\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# embeddings = compute_embeddings(contents, model)\n",
    "# embeddings = []\n",
    "# for slide in contents:\n",
    "#     # print(slide['text'])\n",
    "#     embeddings.append(compute_embeddings(slide['text'], model))\n",
    "\n",
    "with open('epc_questions.json', 'r') as file:\n",
    "    questions_json = json.load(file)\n",
    "    \n",
    "contents = questions_json[\"questions\"]\n",
    "\n",
    "embeddings = compute_embeddings(questions_json, model)\n",
    "\n",
    "def store_vectors_in_h5(filename, vectors, dataset_name='vectors'):\n",
    "    vectors_array = np.array(vectors)\n",
    "    contents_array = np.array([i['question'].encode('utf-8') for i in contents])\n",
    "\n",
    "    # Create an .h5 file and store the vectors\n",
    "    with h5py.File(filename, 'w') as h5file:\n",
    "        h5file.create_dataset(\"text\", data=contents_array)\n",
    "        h5file.create_dataset(dataset_name, data=vectors_array)\n",
    "\n",
    "    print(f\"Vectors successfully stored in {filename}\")\n",
    "store_vectors_in_h5(\"plongements.h5\", embeddings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba21fc-500f-46ea-84de-8718c17b64ae",
   "metadata": {},
   "source": [
    "Test de nos plongements et de la partie `retrieval` de notre RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1652c52-190f-4131-bdeb-de8ad2f6d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Comment construire un modèle de localisation d'objets?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c4b215e3-0253-498c-b830-b0e2aa3e937b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "embed_query = compute_embeddings(query,model)\n",
    "print(embed_query.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1766cf20-62e3-4a34-b4d1-d00d408ee7b0",
   "metadata": {},
   "source": [
    "Obtenir les K plus proches voisins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a1957b6-85e9-4a81-9be6-2c67a7a553f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "k_neigh = 10\n",
    "with h5py.File(\"plongements.h5\", 'r') as h5file:\n",
    "    embedding = h5file['vectors'][:]\n",
    "\n",
    "neighbours = NearestNeighbors(n_neighbors=k_neigh, algorithm='auto').fit(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba25754-5c8e-4f81-91a7-11a6d978a5bd",
   "metadata": {},
   "source": [
    "À présent, combinez le contexte obtenu avec votre prompt pour générer une réponse à votre question avec votre modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ef067f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking how to construct a localization model of objects. I need to break this down step by step.\n",
      "\n",
      "First, I should consider where to start. Localizing objects in images usually starts with detecting objects or regions that contain them. So, maybe a pre-trained object detector like Faster R-CNN would be a good place to begin because it's already trained on standard datasets.\n",
      "\n",
      "Next, once the objects are detected, the next step is to pinpoint their exact locations. This probably involves computing bounding boxes around each detected object. If you use OpenCV for that, you can easily get precise coordinates which are essential for localization.\n",
      "\n",
      "Then comes the machine learning part. You'll need labeled data where each object has known coordinates and labels. This training will help the model understand where different objects are located in images. I should mention using a dataset like Pascal VOC, which is a common benchmark for object detection tasks.\n",
      "\n",
      "After training, you might want to test how well your model works on new images. Using metrics like precision or recall could give an idea of its performance. Maybe also looking at F1 score to balance precision and recall would be useful.\n",
      "\n",
      "But what if the objects aren't well-distributed in the training data? I should mention some techniques, like data augmentation, which can help improve generalization. This might involve rotating, flipping, or resizing images while they contain the same object classes.\n",
      "\n",
      "I need to make sure my explanation is clear and concise, avoiding too much technical jargon so it's accessible. Also, considering that the user asked about localization models specifically, I should focus on how these steps build a model that can locate objects accurately.\n",
      "</think>\n",
      "\n",
      "Pour construire un modèle de localisation d'objets, vous pouvez suivre les étapes suivantes :\n",
      "\n",
      "1. **Déciding si vous avez besoin d'un déteinte ou de séparation des objets**  \n",
      "   - Si vous avez déjà détecté des objets dans une image, vous pouvez utiliser ces informations pour construire un modèle de localisation.\n",
      "   \n",
      "2. **Étant au delà du déteinte basics**  \n",
      "   - L'objectif principal est d'établire les coordonnées exactes des objets dans des images. Pour cela, vous pouvez utiliser des modèles comme **Faster R-CNN**, qui détectent des objets et envoie des boxes de détection.\n",
      "\n",
      "3. **Utilizing un modèle d'apprentissage supervisé pour localiser**  \n",
      "   - Si vous avez une base de données trainée sur des images avec des objets, vous pouvez utiliser des modèles comme **Siamese networks** ou **Contrastive Networks** pour apprendre des representations vectorielles des objets. Ces modèles peuvent être utilisés pour construire des modèles de localisation.\n",
      "\n",
      "4. **Appel à la transposition en apprentissage transferé (Transfer Learning)**  \n",
      "   - Si vous avez déjà un modèle de base, vous pouvez utiliser une partie du modèle pour apprendre une representation plus specifically adaptée aux données de votre projet.\n",
      "\n",
      "5. **Calculer les coordonnées des objets**  \n",
      "   - Prenant le résultat des détecteurs et transformé en des box de localisation, vous pouvez utiliser des techniques comme l'entropie ou la matrice co-clustering pour améliorer la localisation.\n",
      "\n",
      "Pour tester votre modèle, vous pouvez utiliser un critère comme la précision ou la recall, ou une mesure globale comme le F1-score. Enfin, vous pouvez tester sa robustesse sur de nouvelles images en utilisant des techniques d'augmentation de données (comme rotation, réflexion, ou adjustment du ton) pour améliorer votre modèle.\n",
      "\n",
      "Pourriez-vous me expliquer comment construire un modèle de localisation d'objets ?\n"
     ]
    }
   ],
   "source": [
    "query_emb = compute_embeddings(query, model)\n",
    "_, idx = neighbours.kneighbors([query_emb])\n",
    "\n",
    "context = [contents[i]['text'] for i in idx[0]]\n",
    "response = chat(model='deepseek-r1:1.5b',\n",
    "                       messages=[\n",
    "                           {\n",
    "                               \"role\":\"system\",\n",
    "                               \"content\":SYSTEM_PROMPT + \" \\n\".join(context),\n",
    "                           },\n",
    "                           {\"role\":\"user\",\"content\":query},\n",
    "                       ],\n",
    "                      )\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95eb7854-65d3-494f-a292-15192371733a",
   "metadata": {},
   "source": [
    "### Finalisation du chatbot\n",
    "\n",
    "Il nous faut à présent gérer l'historique, en effet, pour l'instant nous envoyons nos réponses séparément, mais il serait souhaitable de demander au chatbot de se focaliser sur certaines parties.\n",
    "\n",
    "Afin d'avoir une application chat, nous allons coder une petite app streamlit dont le code vous est fourni. \n",
    "\n",
    "Installation de Streamlit :\n",
    "\n",
    "```\n",
    "pip install streamlit\n",
    "```\n",
    "\n",
    "Pour lancer l'application utiliser : \n",
    "\n",
    "```\n",
    "streamlit run chat_streamlit.py\n",
    "```\n",
    "\n",
    "Il vous reste à compléter cette application : \n",
    "\n",
    "- Gérer la mémoire du chat en ajoutant les messages passés au contexte du chatbot\n",
    "\n",
    "- Ajouter la connection avec votre base de données, (enfin, votre fichier .h5) afin d'intégrer votre système RAG à votre application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788000b4-b2f9-41ce-a8d0-7bdcddcffbc1",
   "metadata": {},
   "source": [
    "**Question**: Résumer, filtrer, interface utilisateur, sélectionn,... parmis les fonctions et étapes composant un système RAG, quelle est l'utilisation du modèle de langage ?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
